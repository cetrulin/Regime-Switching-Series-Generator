{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import yaml\n",
    "import time\n",
    "import random\n",
    "from enum import Enum\n",
    "import statsmodels.tsa.api as smt\n",
    "import logging\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "from src import generator_utils as gutils\n",
    "from src.model import Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\suare\\\\PycharmProjects\\\\RegimeSwitchingSeriesGenerator\\\\notebooks',\n",
       " 'C:\\\\Users\\\\suare\\\\PycharmProjects\\\\RegimeSwitchingSeriesGenerator',\n",
       " 'C:\\\\Users\\\\suare\\\\PycharmProjects\\\\CryptoDataPreprocessing',\n",
       " 'C:\\\\Users\\\\suare\\\\Anaconda3\\\\python37.zip',\n",
       " 'C:\\\\Users\\\\suare\\\\Anaconda3\\\\DLLs',\n",
       " 'C:\\\\Users\\\\suare\\\\Anaconda3\\\\lib',\n",
       " 'C:\\\\Users\\\\suare\\\\Anaconda3',\n",
       " '',\n",
       " 'C:\\\\Users\\\\suare\\\\Anaconda3\\\\lib\\\\site-packages',\n",
       " 'C:\\\\Users\\\\suare\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32',\n",
       " 'C:\\\\Users\\\\suare\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'C:\\\\Users\\\\suare\\\\Anaconda3\\\\lib\\\\site-packages\\\\Pythonwin',\n",
       " 'C:\\\\Users\\\\suare\\\\Anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\extensions',\n",
       " 'C:\\\\Users\\\\suare\\\\.ipython',\n",
       " '..']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_DICT_NAMES = 'fitted_'\n",
    "\n",
    "# Logger\n",
    "logging.basicConfig()\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "class Switch(Enum):\n",
    "    NONE = -1\n",
    "    GRADUAL = 0\n",
    "    ABRUPT = 1\n",
    "    PREDEFINED = 2\n",
    "\n",
    "def instantiate_model(config, show_plt, file_config):\n",
    "    \"\"\"\n",
    "    This handles each thread in 'instantiate_models'\n",
    "    :param config: from YAML file\n",
    "    :param show_plt: plot series?\n",
    "    :param file_config: list of ids, files and probabilities.\n",
    "    :return: model and desc tuple\n",
    "    \"\"\"\n",
    "    # 1. Read dataset for model\n",
    "    counter, file, preconf, prob = file_config\n",
    "    df = pd.read_csv(os.path.join(config['path'], file), sep=';')  # , header=None)\n",
    "    # df.columns = config['cols']\n",
    "    df.set_index(keys=config['index_col'], drop=True, inplace=True)\n",
    "\n",
    "    # 2. Clean nulls and select series\n",
    "    raw_series = df[[config['sim_col']]]  # .dropna()\n",
    "    raw_returns_series = 100 * df[[config['sim_col']]].pct_change()  # .dropna()\n",
    "    # the returns later are calculated in a different way and they use log scale\n",
    "\n",
    "    # Plot initial df and returns\n",
    "    if show_plt:\n",
    "        gutils.plot_input(df, 'Raw dataset')\n",
    "        gutils.plot_input(raw_series, 'Prices')\n",
    "        gutils.plot_input(raw_returns_series, 'Returns')\n",
    "\n",
    "    # 3. Prepare Model and return it to be added to a dictionary\n",
    "    return Model(id=counter, raw_input_path=os.path.join(config['path'], file),\n",
    "                 input_ts=gutils.prepare_raw_series(config['parsing_mode'], raw_series),\n",
    "                 rec_price=list(raw_series[config['sim_col']])[-1],  # last fitting price will be used for reconstruction\n",
    "                 probability=prob,\n",
    "                 ARMAGARCH_preconf=preconf),  f'{MODEL_DICT_NAMES}{counter}'\n",
    "\n",
    "\n",
    "def instantiate_models(config: dict(), show_plt: bool = True):\n",
    "    \"\"\"\n",
    "    This function loads the initial series to feed them to models.\n",
    "    :param config: from YAML file\n",
    "    :param show_plt: plot series?\n",
    "    :return: dict of series\n",
    "    \"\"\"\n",
    "    # Load raw time series for the pre-training of the models\n",
    "    logging.info('Load models...')\n",
    "    pool = multiprocessing.Pool(len(config['files']))  # gutils.MyPool(1)\n",
    "    mapped = pool.map(partial(instantiate_model, config, show_plt), config['files'])\n",
    "    series_dict = dict(map(reversed, tuple(mapped)))\n",
    "    return series_dict\n",
    "\n",
    "\n",
    "def get_best_arma_parameters(ts: list(), config: dict()):\n",
    "    \"\"\"\n",
    "    If selected, this list returns the best ARMA model for the current pre-training period.\n",
    "    Cos and ARMA-GARCH(1,1) may be good enough:\n",
    "        https://stats.stackexchange.com/questions/175400/optimal-lag-order-selection-for-a-garch-model\n",
    "    @:param TS: time series of returns used for pre-training\n",
    "    \"\"\"\n",
    "    best_aic = np.inf\n",
    "    best_order = None\n",
    "    best_mdl = None\n",
    "\n",
    "    for i in range(1, config['pq_rng'] + 1):   # [0,1,2,3,4]\n",
    "        for d in range(config['d_rng']):  # [0] # we'll use arma-garch, so not d (= 0)\n",
    "            for j in range(1, config['pq_rng'] + 1):\n",
    "                try:\n",
    "                    tmp_mdl = smt.ARIMA(ts, order=(i, d, j)).fit(\n",
    "                        method='mle', trend='nc'\n",
    "                    )\n",
    "                    tmp_aic = tmp_mdl.aic\n",
    "                    if tmp_aic < best_aic:\n",
    "                        best_aic = tmp_aic\n",
    "                        best_order = (i, d, j)\n",
    "                        best_mdl = tmp_mdl\n",
    "                except:\n",
    "                    continue\n",
    "    print('aic: {:6.5f} | order: {}'.format(best_aic, best_order))\n",
    "    return best_aic, best_order, best_mdl\n",
    "\n",
    "\n",
    "def fit_model(show_plt: bool, tool_params: dict(), armagarch_lib: dict(), series_model):\n",
    "    \"\"\"\n",
    "    This handles each thread in 'fit_models'\n",
    "    :param tool_params: YAML dict with model params\n",
    "    :param armagarch_lib: library name and environment paths to load an R library for ARMA-GARCH\n",
    "    :param show_plt: plot series?\n",
    "    :param series_model: list of series as an object of Model.\n",
    "    :return: fitted model and description to be added to dictionary\n",
    "    \"\"\"\n",
    "    name_series, current_model = series_model\n",
    "    # logging.info(f'\\n\\n 1. Setting ARMAGARCH library for model {current_model.id}')\n",
    "    if tool_params['param_search'] == 'ARMA':\n",
    "        _, ARMA_order, ARMA_model = get_best_arma_parameters(ts=list(current_model.input_ts), config=tool_params)  #\n",
    "        # ARMA_order = (4, 0, 4)\n",
    "        print(current_model.id)\n",
    "        print('Best parameters are: ')\n",
    "        current_model.set_lags(ARMA_order[0], ARMA_order[1], ARMA_order[2])\n",
    "        print(f'{current_model.get_lags()}')\n",
    "\n",
    "        if show_plt:\n",
    "            gutils.tsplot(ARMA_order.resid, lags=30)\n",
    "            gutils.tsplot(ARMA_order.resid ** 2, lags=30)\n",
    "\n",
    "        logging.info(f'\\n\\n 2. Start fitting process for {current_model.id}')\n",
    "\n",
    "        # Now we can fit the arch model using the best fit ARIMA model parameters. 'o' not in ARMAGARCH\n",
    "        current_model.fit(current_model.input_ts, armagarch_lib, current_model.p, current_model.q)\n",
    "\n",
    "    elif tool_params['param_search'] == 'ARMA_GARCH':\n",
    "        best_aic, best_order, best_model = current_model.get_best(current_model.input_ts, tool_params, armagarch_lib)\n",
    "        current_model.set_lags(*best_order)\n",
    "        current_model.set_spec_from_model(best_model)\n",
    "        # current_model.fit(current_model.input_ts, armagarch_lib,\n",
    "        #                   current_model.p, current_model.q, current_model.g_p, current_model.g_q)  # not needed\n",
    "        logging.info('model {} -> aic: {:6.5f} | order: {}'.format(current_model.id, best_aic, best_order))\n",
    "    else:\n",
    "        logging.critical('param_search must be provided in config.yaml. Values should be \"ARMA\" or \"ARMA_GARCH\"\\n\\n')\n",
    "\n",
    "    return current_model, name_series  # name_series = f'{MODEL_DICT_NAMES}{counter}'\n",
    "\n",
    "\n",
    "def fit_models(series_dict: dict(), input_data_conf: dict(), params: dict(),\n",
    "               armagarch_lib: dict(), show_plt: bool = False):\n",
    "    \"\"\"\n",
    "    This function triggers the selection of the best parameters and fitting of n models\n",
    "     (one model per dataset added to the YAML config file).\n",
    "    :param series_dict - datasets as a single column DF to fit the models\n",
    "    :param armagarch_lib: library name and environment paths to load an R library for ARMA-GARCH\n",
    "    :param input_data_conf - dictionary from YAML with input datasets-related configuration\n",
    "    :param params: YAML dict with model params\n",
    "    :param plot - plot model?\n",
    "    :return list of fitted models\n",
    "    \"\"\"\n",
    "    # Fit models in parallel\n",
    "    logging.info('Fitting models...')\n",
    "    n_threads = 1\n",
    "    pool = gutils.MyPool(n_threads)  # multiprocessing.Pool(processes=len(input_data_conf['files']))\n",
    "    mapped = pool.map(partial(fit_model, show_plt, params, armagarch_lib), series_dict.items())\n",
    "    return dict(map(reversed, tuple(mapped)))\n",
    "\n",
    "\n",
    "def update_weights(w, switch_sharpness):\n",
    "    \"\"\"\n",
    "    This function updates weights each iteration depending on the sharpness of the current switch.\n",
    "    :param w: tuple of weights\n",
    "    :param switch_sharpness: speed of changes\n",
    "    :return: tuple of weights updated.\n",
    "    \"\"\"\n",
    "    if switch_sharpness < 0.1:\n",
    "        print('Minimum switch abrupcy is 0.1, so this is the value being used. ')\n",
    "        switch_sharpness = 0.1\n",
    "    incr = switch_sharpness\n",
    "    w = (w[0] - incr, w[1] + incr)\n",
    "\n",
    "    # see for reference get_weight and reset_weights.\n",
    "    w = (0 if w[0] <= 0 else w[0], 1 if w[1] >= 1 else w[1])  # deal with numbers out of range\n",
    "    return w\n",
    "\n",
    "\n",
    "def reset_weights():\n",
    "    \"\"\"\n",
    "    This function init weights (or different, depending of gradual or abrupt drifts)\n",
    "    :return default/initial weight.\n",
    "    \"\"\"\n",
    "    w = (1, 0)  # Initialize\n",
    "    return w\n",
    "\n",
    "\n",
    "def get_event_dict(counter, current_model, new_model, new_switch_type, switch_type, tool_params, w):\n",
    "    return {'n_row': counter,\n",
    "            'new_switch': new_switch_type.name,\n",
    "            'cur_switch': switch_type.name if switch_type.name != 'PREDEFINED'\n",
    "            else '_'.join([switch_type.name, str(int(100/(tool_params['defined_drift_sharpness']*100)) - 1)]),\n",
    "            'weights': w,\n",
    "            'current_model_id': current_model.id,  # Add p,o,q to this?\n",
    "            'new_model_id': -1 if new_model is None else new_model.id}\n",
    "\n",
    "\n",
    "def random_switch(switch_prob: float, abrupt_prob: float):\n",
    "    \"\"\"\n",
    "    This function flips coins and return if a drift should be triggered and its type.\n",
    "    :param switch_prob\n",
    "    :param abrupt_prob\n",
    "    :return switch event that takes in place. integer represented by an enum.\n",
    "    \"\"\"\n",
    "    if random.random() < switch_prob:\n",
    "        # Switch ?\n",
    "        if random.random() < abrupt_prob:\n",
    "            return Switch.ABRUPT\n",
    "        else:\n",
    "            return Switch.GRADUAL\n",
    "    else:\n",
    "        # Otherwise\n",
    "        return Switch.NONE\n",
    "\n",
    "\n",
    "def start_switch(counter, conf):\n",
    "    \"\"\"\n",
    "    This function manages the decision of switching from one model to another.\n",
    "    \"\"\"\n",
    "    conf['defined_drift_sharpness'] = None\n",
    "\n",
    "    if conf['use_transition_map']:\n",
    "        # Set no-switch by default\n",
    "        switch_shp = (conf['gradual_drift_sharpness'], conf['abrupt_drift_sharpness'], conf['defined_drift_sharpness'])\n",
    "        new_switch_type, switch_shp, conf, switch_to = Switch.NONE, switch_shp, conf, None\n",
    "\n",
    "        for (it, length, to_mdl) in conf['transition_map']:\n",
    "            if counter == it:\n",
    "                new_switch_type = Switch.PREDEFINED\n",
    "                conf['defined_drift_sharpness'] = 100.0 / float(length + 1) / 100.0\n",
    "                switch_shp = (conf['gradual_drift_sharpness'], conf['abrupt_drift_sharpness'],\n",
    "                              conf['defined_drift_sharpness'])\n",
    "                switch_to = to_mdl\n",
    "                return new_switch_type, switch_shp, conf, switch_to\n",
    "\n",
    "            elif counter < it:\n",
    "                return new_switch_type, switch_shp, conf, switch_to\n",
    "    else:\n",
    "        # No new switch if there is one already in progress\n",
    "        new_switch_type = random_switch(conf['switching_probability'], conf['abrupt_drift_prob'])\n",
    "\n",
    "    switch_shp = [conf['gradual_drift_sharpness'], conf['abrupt_drift_sharpness'], conf['defined_drift_sharpness']]\n",
    "    return new_switch_type, switch_shp, conf, None\n",
    "\n",
    "\n",
    "def get_new_model(current_id: int, config: dict()):\n",
    "    \"\"\"\n",
    "    This function picks a new model based in their probability to be selected (equal for all by now).\n",
    "    :param current_id - so there is an actual drift and the id is not repeated.\n",
    "    :param config - for probabilities\n",
    "    :return new model id\n",
    "    \"\"\"\n",
    "    # NOT TO BE DEVELOPED (YET)\n",
    "    # Just here in the case of having different probabilities of transitioning per series.\n",
    "    # for i in range(len(config)):\n",
    "    # for i in range(len(config)):\n",
    "    #     config[i][1]  # TOD: ENUMERATOR SO TRANSITION_PROBABILITIES_POS == 1\n",
    "    new_model_id = random.randrange(1, len(config)+1)\n",
    "    return get_new_model(current_id, config) if current_id == new_model_id else new_model_id\n",
    "\n",
    "\n",
    "def prepare_and_export(global_params, output_format, rc, ts, reconstruction_price):\n",
    "    \"\"\"\n",
    "    This function reconstruct prices, adds noise and and exports a csv\n",
    "    :param global_params: config params\n",
    "    :param output_format: info about file to be exported\n",
    "    :param rc: registered events\n",
    "    :param ts: time series generated\n",
    "    :param reconstruction_price: price for reconstruction\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    logging.info('Reconstructing prices and adding noise...')\n",
    "    rc['ret_ts'] = ts\n",
    "\n",
    "    # 5.1 noise over returns\n",
    "    ts_gn, ts_snr = gutils.add_noise(global_params['white_noise_level'], list(rc['ret_ts']))\n",
    "\n",
    "    # 5.2 reconstruction\n",
    "    rc['ts'] = gutils.reconstruct(ts, init_val=reconstruction_price)\n",
    "    # rc['ts_mult'] = gutils.reconstruct(ts * 5, init_val=reconstruction_price)\n",
    "    # Gaussian noise & reconstruct\n",
    "    rc['ts_n1_pre'] = gutils.reconstruct(ts_gn, init_val=reconstruction_price)\n",
    "    # SNR and White Gaussian Noise & reconstruct\n",
    "    rc['ts_n2_pre'] = gutils.reconstruct(ts_snr, init_val=reconstruction_price)\n",
    "\n",
    "    # 5.3 noise post-reconstruction (over prices)\n",
    "    ts_gn, ts_snr = gutils.add_noise(global_params['white_noise_level'], list(rc['ts']))\n",
    "    rc['ts_n1_post'] = ts_gn  # Gaussian noise\n",
    "    rc['ts_n2_post'] = ts_snr  # SNR and White Gaussian Noise\n",
    "\n",
    "    # 6 Final simulation (TS created) and a log of the regime changes (RC) to CSV files\n",
    "    rc[output_format['cols']].to_csv(os.sep.join([output_format['path'],\n",
    "                                                  output_format['ts_name'] + str(int(time.time())) + '.csv']),\n",
    "                                     index=False)\n",
    "\n",
    "\n",
    "def prepare_and_export_2(global_params, output_format, rc, ts, reconstruction_price):\n",
    "    \"\"\"\n",
    "    This function reconstruct prices, adds noise and and exports a csv\n",
    "    :param global_params: config params\n",
    "    :param output_format: info about file to be exported\n",
    "    :param rc: registered events\n",
    "    :param ts: time series generated\n",
    "    :param reconstruction_price: price for reconstruction\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    logging.info('Reconstructing prices and adding noise...')\n",
    "    rc['ret_ts'] = ts\n",
    "\n",
    "    print(rc.head())\n",
    "\n",
    "    # 5.1 noise over returns\n",
    "    ts_gn, ts_snr = gutils.add_noise(global_params['white_noise_level'], list(rc['ret_ts']))\n",
    "\n",
    "    # 5.2 reconstruction\n",
    "    rc['ts'] = gutils.reconstruct(ts, init_val=reconstruction_price)\n",
    "\n",
    "    # Gaussian noise & reconstruct\n",
    "    rc['ts_n1_pre'] = gutils.reconstruct(ts_gn, init_val=reconstruction_price)\n",
    "    # SNR and White Gaussian Noise & reconstruct\n",
    "    rc['ts_n2_pre'] = gutils.reconstruct(ts_snr, init_val=reconstruction_price)\n",
    "\n",
    "    # 5.3 noise post-reconstruction (over prices)\n",
    "    ts_gn, ts_snr = gutils.add_noise(global_params['white_noise_level'], list(rc['ts']))\n",
    "    rc['ts_n1_post'] = ts_gn  # Gaussian noise\n",
    "    rc['ts_n2_post'] = ts_snr  # SNR and White Gaussian Noise\n",
    "\n",
    "    # 6 Final simulation (TS created) and a log of the regime changes (RC) to CSV files\n",
    "    rc[output_format['cols']].to_csv(os.sep.join([output_format['path'],\n",
    "                                                  output_format['ts_name'] + str(int(time.time())) + '.csv']),\n",
    "                                     index=False)\n",
    "\n",
    "def reconstruct(filename: str):\n",
    "    import os\n",
    "\n",
    "    # Read YAML file\n",
    "    with open(\"config.yaml\", 'r') as stream:\n",
    "        config = yaml.safe_load(stream)\n",
    "        input_data_config = config['input']\n",
    "        global_params = config['params']\n",
    "        out_format = config['output']\n",
    "        armagarch_lib = {'lib': 'rugarch', 'env': config['env']['r_libs_path']}\n",
    "\n",
    "    df = pd.read_csv(os.sep.join([out_format['path'], filename]))\n",
    "    # models_dict['fitted_1']  # -> 227.52\n",
    "    # models_dict['fitted_2']  # -> 10850.26\n",
    "    # models_dict['fitted_3']  # -> 0.3199\n",
    "    # models_dict['fitted_4']  # -> 164.91\n",
    "    prepare_and_export_2(global_params, out_format, rc=df, ts=df.ret_ts, reconstruction_price=227.52)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def switching_process(tool_params: dict(), models: dict(), data_config: dict(), armagarch_lib, show_plt: bool):\n",
    "    \"\"\"\n",
    "    This function computes transitions between time series and returns the resulting time series.\n",
    "    :param tool_params: info regarding to stitches from yaml file\n",
    "    :param models: fitted models\n",
    "    :param data_config: datasets info from yaml file\n",
    "    :param show_plt: plot resulting ts?\n",
    "    :param armagarch_lib: TSpackage for R library to use\n",
    "    :return: ts - series generated\n",
    "    :rerurn: rc - dataframe of events (switches flagged, models used and weights)\n",
    "    \"\"\"\n",
    "    # Init params\n",
    "    switch_type = Switch.NONE\n",
    "    no_switch = Switch.NONE, None, tool_params, None\n",
    "    use_sig_w = tool_params['w_func'] == 'sig'\n",
    "\n",
    "    # Start with model A as initial model\n",
    "    current_model = models[f'{MODEL_DICT_NAMES}{1}']  # first model -> current_model = A (randomly chosen)\n",
    "    new_model = None\n",
    "\n",
    "    # Initialize main series\n",
    "    ts = list()  # rec_ts = list()\n",
    "    rc = list()\n",
    "    w = reset_weights()  # tuple (current, new) of model weights.\n",
    "    sig_w = reset_weights()\n",
    "    state_counter = 0\n",
    "    # tool_params['transition_map']\n",
    "    logging.info('Start of the context-switching generative process:')\n",
    "    for it_counter in range(tool_params['periods']):\n",
    "        # 1 Start forecasting in 1 step horizons using the current model\n",
    "        old_model_forecast = current_model.forecast(list(current_model.input_ts)\n",
    "                                                    if it_counter < max(current_model.get_lags()) else list(ts),\n",
    "                                                    armagarch_lib)\n",
    "        new_switch_type, new_switch_shp, tool_params, switch_to = no_switch \\\n",
    "            if (0 < w[1] < 1 or state_counter <= tool_params['min_model_len']) \\\n",
    "            else start_switch(it_counter, tool_params)\n",
    "\n",
    "        # 2 In case of switch, select a new model and reset weights: (1.0, 0.0) at the start (no changes) by default.\n",
    "        if new_switch_type.value >= 0:\n",
    "            logging.info(f'There is a {new_switch_type.name} switch.')\n",
    "            switch_type, switch_shp = new_switch_type, new_switch_shp\n",
    "            # 'switch_to' is only used if transition_maps are enabled.\n",
    "            new_mdl_number = get_new_model(current_model.id, data_config[\"files\"]) if switch_to is None else switch_to\n",
    "            new_model = models[f'{MODEL_DICT_NAMES}{new_mdl_number}'] \\\n",
    "\n",
    "            w = update_weights(w=reset_weights(), switch_sharpness=switch_shp[switch_type.value])\n",
    "            sig_w = (gutils.get_sigmoid()[int(w[0]*100)], 1 - gutils.get_sigmoid()[int(w[0]*100)])  # kernel to sig func\n",
    "\n",
    "        # 3 Log switches and events\n",
    "        rc.append(get_event_dict(it_counter, current_model, new_model, new_switch_type, switch_type, tool_params,\n",
    "                                 sig_w if use_sig_w else w))\n",
    "        assert (sig_w[0] + sig_w[1] if use_sig_w else w[0] + w[1]) == 1\n",
    "\n",
    "        # 4 if it's switching (started now or in other iteration), then forecast with new model and get weighted average\n",
    "        if 0 < w[1] < 1:\n",
    "            # print('Update weights:')\n",
    "            # Forecast and expand current series (current model is the old one, this becomes current when weight == 1)\n",
    "            new_model_forecast = new_model.forecast(list(new_model.input_ts)\n",
    "                                                    if it_counter < max(new_model.get_lags()) else list(ts),\n",
    "                                                    armagarch_lib)\n",
    "            ts.append(old_model_forecast * (sig_w[0] if use_sig_w else w[0]) +\n",
    "                      new_model_forecast * (sig_w[1] if use_sig_w else w[1]))\n",
    "\n",
    "            w = update_weights(w, switch_shp[switch_type.value])\n",
    "            sig_w = (gutils.get_sigmoid()[int(w[0]*100)], 1 - gutils.get_sigmoid()[int(w[0]*100)])  # kernel to sig func\n",
    "            # print(sig_w)\n",
    "\n",
    "            if w[1] == 1:\n",
    "                current_model = new_model\n",
    "                new_model = None\n",
    "                state_counter = 0  # reset of counter for duration of model\n",
    "                w = reset_weights()\n",
    "                sig_w = reset_weights()\n",
    "                switch_type = Switch.NONE\n",
    "\n",
    "        # 3. Otherwise, use the current forecast\n",
    "        else:\n",
    "            ts.append(old_model_forecast)\n",
    "\n",
    "        state_counter = state_counter + 1\n",
    "        # logging.info(f'Period {it_counter}: {ts}')\n",
    "\n",
    "    # 4 Plot simulations\n",
    "    if show_plt:\n",
    "        gutils.plot_results(ts)\n",
    "\n",
    "    return pd.Series(ts),  pd.DataFrame(rc)\n",
    "\n",
    "def parse_yaml():\n",
    "    \"\"\" This function parses the config file and returns options, paths, etc.\"\"\"\n",
    "    # Read YAML file\n",
    "    with open(\"C:\\\\Users\\\\suare\\\\PycharmProjects\\\\RegimeSwitchingSeriesGenerator\\\\config.yaml\", 'r') as stream:\n",
    "        config = yaml.safe_load(stream)\n",
    "        input_data_config = config['input']\n",
    "        global_params = config['params']\n",
    "        out_format = config['output']\n",
    "        plot = config['plot']\n",
    "        armagarch_lib = {'lib': 'rugarch', 'env': config['env']['r_libs_path']}\n",
    "        print(config)\n",
    "\n",
    "    return input_data_config, global_params, out_format, armagarch_lib, plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'params': {'periods': 150000, 'switching_probability': 0.05, 'min_model_len': 1, 'abrupt_drift_prob': 0.25, 'gradual_drift_sharpness': 0.1, 'abrupt_drift_sharpness': 0.7, 'white_noise_level': 0.05, 'w_func': 'sig', 'param_search': 'ARMA_GARCH', 'pq_rng': 10, 'd_rng': 1, 'garch_pq_rng': 5, 'use_transition_map': True, 'transition_map': [[10, 10, 2], [5200, 100, 1], [24500, 10, 3], [41100, 100, 1], [52700, 10, 3], [67200, 100, 1], [83500, 10, 2], [98800, 100, 4], [114400, 10, 3], [133000, 10, 4]]}, 'input': {'path': '.\\\\\\\\data\\\\\\\\', 'files': [[1, 'aapl\\\\\\\\APPLE_[2018-08-01_to_2018-09-11]_5min.csv', [4, 0, 3, 1, 1], 0.25], [2, 'btc\\\\\\\\BITCOIN_[2019-07-01_to_2019-07-15]_5min.csv', [8, 0, 6, 2, 4], 0.25], [3, 'xrp\\\\\\\\RIPPLE_[2019-07-01_to_2019-08-01]_5min.csv', [9, 0, 10, 1, 3], 0.25], [4, 'efts\\\\\\\\5min-level\\\\\\\\DOWJONES\\\\\\\\DOWJONES_[2015-08-01_to_2015-08-31]_market_hours.csv', [7, 0, 9, 2, 4], 0.25]], 'sim_col': 'close', 'index_col': 'datetime', 'parsing_mode': 'returns'}, 'output': {'path': '.\\\\\\\\output', 'ts_name': 'timeseries_created_', 'cols': ['n_row', 'new_switch', 'cur_switch', 'current_model_id', 'new_model_id', 'weights', 'ts', 'ret_ts', 'ts_n1_pre', 'ts_n2_pre', 'ts_n1_post', 'ts_n2_post']}, 'plot': False, 'env': {'r_libs_path': 'C:/Users/suare/OneDrive/Documents/asuare/R/win-library/3.6'}}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This function coordinates the whole process.\n",
    "1. It loads examples series and pre-train ad many models as series received.\n",
    "2. It triggers the switching and generation process and plots the resulting series.\n",
    "3. It adds white and gaussian noise.\n",
    "4. It exports the resulting time series without and with noise, and the events/switches to a CSV.\n",
    "\"\"\"\n",
    "# 0 Read from YAML file\n",
    "input_data_config, global_params, output_format, armagarch_lib, plt_flag = parse_yaml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Load models...\n"
     ]
    }
   ],
   "source": [
    "# 1 Get dict of series and their probabilities calling instantiate_models.\n",
    "#   The objects in this dictionary contain series of returns on log scale.\n",
    "# 2 Then, pre-train GARCH models by looking at different series\n",
    "# models_dict = fit_models(series_dict=instantiate_models(config=input_data_config, show_plt=plt_flag),\n",
    "#                          input_data_conf=input_data_config,\n",
    "#                          params=global_params, armagarch_lib=armagarch_lib, show_plt=plt_flag)\n",
    "\n",
    "plt_flag = False\n",
    "series_dict=instantiate_models(config=input_data_config, show_plt=plt_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# Fit models in parallel\n",
    "logging.info('Fitting models...')\n",
    "n_threads = 1\n",
    "pool = gutils.MyPool(n_threads)  # multiprocessing.Pool(processes=len(input_data_conf['files']))\n",
    "mapped = pool.map(partial(fit_model, plt_flag, global_params, armagarch_lib), series_dict.items())\n",
    "models_dict = dict(map(reversed, tuple(mapped)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_config, global_params, output_format, armagarch_lib, plt_flag = parse_yaml()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Once the models are pre-train, these are used for simulating the final series.\n",
    "# At every switch, the model that generates the final time series will be different.\n",
    "ts, rc = switching_process(tool_params=global_params, models=models_dict,\n",
    "                           data_config=input_data_config, armagarch_lib=armagarch_lib, show_plt=plt_flag)\n",
    "\n",
    "# 4 Plot simulations\n",
    "if plt_flag:\n",
    "    gutils.plot_results(ts)\n",
    "\n",
    "# 5 Add noise (gaussian noise and SNR) pre-reconstruction, reconstruct prices and add noise post-reconstruction\n",
    "# 6 and export\n",
    "pc = rc.copy()\n",
    "pc['ret_ts'] = ts\n",
    "pc.to_csv(os.sep.join([output_format['path'], output_format['ts_name'] + str(int(time.time())) + '.csv']), index=False)\n",
    "# 6 Final simulation (TS created) and a log of the regime changes (RC) to CSV files\n",
    "prepare_and_export(global_params, output_format, rc, ts,\n",
    "                   reconstruction_price=models_dict['fitted_1'].rec_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
